{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>CSE3024 Lab 3: Inverted Index Creation and Searching </center>\n",
    "<h3 align=\"right\">Faraz Suhail</h3> \n",
    "<h3 align=\"right\">19BCE1525</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ques 1.\tBuild the inverted index for the following documents:\n",
    "ID1: Selenium is a portable framework for testing web applications;\n",
    "\n",
    "ID2: Beautiful Soup is useful for web scraping with selenium;\n",
    "\n",
    "ID3: It is a python-package for parsing the pages using selenium\n",
    "\n",
    "ID4: Java programming can be used for web applications\n",
    "\n",
    "ID5: scraping web and crawling web is useful with selenium framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "documents = ['ID1','ID2','ID3','ID4','ID5'] \n",
    "index={}\n",
    "\n",
    "for id, doc in enumerate(documents): \n",
    "   filename = doc+\".txt\" \n",
    "   with open(filename,'r') as fp: \n",
    "    data = \"\".join(fp.readlines()) \n",
    "    data = data.lower() \n",
    "    ext_words = re.findall(r\"([a-z0-9-]+)\",data) \n",
    "    for pos,word in enumerate(ext_words): \n",
    "      if word[-1]=='s': \n",
    "        if word[:-1] in index: \n",
    "          word = word[:-1] \n",
    "        elif word[:-2] in index: \n",
    "          word = word[:-2] \n",
    "\n",
    "      if word not in index: \n",
    "        index[word]={ \"freq\":1, \"listing\": [(id+1,pos)] } \n",
    "      else: \n",
    "        index[word]['freq']+=1 \n",
    "        index[word]['listing'].append((id+1,pos)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a : {'freq': 2, 'listing': [(1, 2), (3, 2)]}\n",
      "and : {'freq': 1, 'listing': [(5, 2)]}\n",
      "applications : {'freq': 2, 'listing': [(1, 8), (4, 7)]}\n",
      "be : {'freq': 1, 'listing': [(4, 3)]}\n",
      "beautiful : {'freq': 1, 'listing': [(2, 0)]}\n",
      "can : {'freq': 1, 'listing': [(4, 2)]}\n",
      "crawling : {'freq': 1, 'listing': [(5, 3)]}\n",
      "for : {'freq': 4, 'listing': [(1, 5), (2, 4), (3, 5), (4, 5)]}\n",
      "framework : {'freq': 1, 'listing': [(1, 4)]}\n",
      "is : {'freq': 4, 'listing': [(1, 1), (2, 2), (3, 1), (5, 5)]}\n",
      "it : {'freq': 1, 'listing': [(3, 0)]}\n",
      "java : {'freq': 1, 'listing': [(4, 0)]}\n",
      "package : {'freq': 1, 'listing': [(3, 4)]}\n",
      "pages : {'freq': 1, 'listing': [(3, 8)]}\n",
      "parsing : {'freq': 1, 'listing': [(3, 6)]}\n",
      "portable : {'freq': 1, 'listing': [(1, 3)]}\n",
      "programming : {'freq': 1, 'listing': [(4, 1)]}\n",
      "python : {'freq': 1, 'listing': [(3, 3)]}\n",
      "scraping : {'freq': 2, 'listing': [(2, 6), (5, 0)]}\n",
      "selenium : {'freq': 1, 'listing': [(1, 0)]}\n",
      "soup : {'freq': 1, 'listing': [(2, 1)]}\n",
      "testing : {'freq': 1, 'listing': [(1, 6)]}\n",
      "the : {'freq': 1, 'listing': [(3, 7)]}\n",
      "used : {'freq': 1, 'listing': [(4, 4)]}\n",
      "useful : {'freq': 2, 'listing': [(2, 3), (5, 6)]}\n",
      "web : {'freq': 5, 'listing': [(1, 7), (2, 5), (4, 6), (5, 1), (5, 4)]}\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict \n",
    "index = OrderedDict(sorted(index.items())) \n",
    "with open(\"inverted.txt\",'w') as fp: \n",
    "  for key in index: \n",
    "    print(f\"{key} : {index[key]}\") \n",
    "    fp.write(f\"{key} : {index[key]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ques 2.\tSearch following words using the inverted index The output should be the document ids containing the search keywords\n",
    "\n",
    "a.\tSelenium AND web\n",
    "\n",
    "b.\tSelenium\n",
    "\n",
    "c.\tPython OR java\n",
    "\n",
    "d.\tWeb AND crawl\n",
    "\n",
    "e.\t!(Selenium)\n",
    "\n",
    "### Part a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4FEx0a9xrx36",
    "outputId": "ab521ea1-26c3-4859-a9c1-9f572e3cc2c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found in doc1.txt\n",
      "No match found in doc2.txt\n",
      "No match found in doc3.txt\n",
      "No match found in doc4.txt\n",
      "No match found in doc5.txt\n",
      "\n",
      "\n",
      "Answer: \n",
      "\n",
      "selenium : {'freq': 1, 'listing': [(1, 0)]}\n",
      "web : {'freq': 1, 'listing': [(1, 0)]}\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "documents =['doc1','doc2','doc3','doc4','doc5'] \n",
    "index={}\n",
    "for id,doc in enumerate(documents): \n",
    "   filename = doc+\".txt\" \n",
    "   with open(filename,'r') as fp: \n",
    "    data = \"\".join(fp.readlines()) \n",
    "    data = data.lower() \n",
    "    #print(len(data))\n",
    "    if re.findall(r\"\\bselenium\\b\", data) and re.findall(r\"\\bweb\\b\", data):\n",
    "      print(\"Match found in\", filename)\n",
    "      ext_words1 = re.findall(r\"\\bselenium\\b\", data) \n",
    "      ext_words2 = re.findall(r\"\\bweb\\b\", data) \n",
    "      for pos,word in enumerate(ext_words1): \n",
    "        if word not in index: \n",
    "          index[word]={ \"freq\":1, \"listing\": [(id+1,pos)] } \n",
    "        else: \n",
    "          index[word]['freq']+=1 \n",
    "          index[word]['listing'].append((id+1,pos)) \n",
    "      for pos,word in enumerate(ext_words2): \n",
    "        if word not in index: \n",
    "          index[word]={ \"freq\":1, \"listing\": [(id+1,pos)] } \n",
    "        else: \n",
    "          index[word]['freq']+=1 \n",
    "          index[word]['listing'].append((id+1,pos)) \n",
    "    else:\n",
    "     print(\"No match found in\", filename) \n",
    "print(\"\\n\")    \n",
    "from collections import OrderedDict \n",
    "index = OrderedDict(sorted(index.items())) \n",
    "with open(\"inverted.txt\",'w') as fp:\n",
    "  print(\"Answer: \\n\") \n",
    "  for key in index: \n",
    "    print(f\"{key} : {index[key]}\") \n",
    "    fp.write(f\"{key} : {index[key]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9FI5RzBrNC4"
   },
   "source": [
    "### Part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDTaCOLAryxg",
    "outputId": "46b61780-7055-4e4d-f7a3-08f21322534b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soup : {'freq': 1, 'listing': [(2, 0)]}\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "documents =['doc1','doc2','doc3','doc4','doc5'] \n",
    "index={}\n",
    "for id,doc in enumerate(documents): \n",
    "   filename = doc+\".txt\" \n",
    "   with open(filename,'r') as fp: \n",
    "    data = \"\".join(fp.readlines()) \n",
    "    data = data.lower() \n",
    "    #print(len(data))\n",
    "    ext_words = re.findall(r\"\\bsoup\\b\", data)\n",
    "    for pos,word in enumerate(ext_words): \n",
    "      if word not in index: \n",
    "        index[word]={ \"freq\":1, \"listing\": [(id+1,pos)] } \n",
    "      else: \n",
    "        index[word]['freq']+=1 \n",
    "        index[word]['listing'].append((id+1,pos)) \n",
    "from collections import OrderedDict \n",
    "index = OrderedDict(sorted(index.items())) \n",
    "with open(\"inverted.txt\",'w') as fp: \n",
    "  for key in index: \n",
    "    print(f\"{key} : {index[key]}\") \n",
    "    fp.write(f\"{key} : {index[key]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wM0nzKKpfKp5"
   },
   "source": [
    "### Part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jD3WJpg5fNuq",
    "outputId": "d02c214f-f381-43ba-de49-a23f65270310"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java : {'freq': 1, 'listing': [(4, 0)]}\n",
      "python : {'freq': 1, 'listing': [(3, 0)]}\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "documents =['doc1','doc2','doc3','doc4','doc5'] \n",
    "index={}\n",
    "for id,doc in enumerate(documents): \n",
    "   filename = doc+\".txt\" \n",
    "   with open(filename,'r') as fp: \n",
    "    data = \"\".join(fp.readlines()) \n",
    "    data = data.lower() \n",
    "    #print(len(data))\n",
    "    ext_words1 = re.compile(r\"\\bpython\\b | \\bjava\\b\",flags=re.I | re.X)\n",
    "    ext_words2=ext_words1.findall(data)\n",
    "    for pos,word in enumerate(ext_words2): \n",
    "      if word not in index: \n",
    "        index[word]={ \"freq\":1, \"listing\": [(id+1,pos)] } \n",
    "      else: \n",
    "        index[word]['freq']+=1 \n",
    "        index[word]['listing'].append((id+1,pos)) \n",
    "from collections import OrderedDict \n",
    "index = OrderedDict(sorted(index.items())) \n",
    "with open(\"inverted.txt\",'w') as fp: \n",
    "  for key in index: \n",
    "    print(f\"{key} : {index[key]}\") \n",
    "    fp.write(f\"{key} : {index[key]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwJhLIrrrmKM"
   },
   "source": [
    "### Part d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jLEdJat-rv9O",
    "outputId": "7594f609-8b9c-45c7-9630-9c9b7e496799"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No match found in doc1.txt\n",
      "No match found in doc2.txt\n",
      "No match found in doc3.txt\n",
      "No match found in doc4.txt\n",
      "No match found in doc5.txt\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "documents =['doc1','doc2','doc3','doc4','doc5'] \n",
    "index={}\n",
    "for id,doc in enumerate(documents): \n",
    "   filename = doc+\".txt\" \n",
    "   with open(filename,'r') as fp: \n",
    "    data = \"\".join(fp.readlines()) \n",
    "    data = data.lower() \n",
    "    #print(len(data))\n",
    "    if re.findall(r\"\\bweb\\b\", data) and re.findall(r\"\\bcraw\\b\", data):\n",
    "      print(\"Match found in\", filename)\n",
    "      ext_words1 = re.findall(r\"\\bweb\\b\", data) \n",
    "      ext_words2 = re.findall(r\"\\bcraw\\b\", data) \n",
    "      for pos,word in enumerate(ext_words1): \n",
    "        if word not in index: \n",
    "          index[word]={ \"freq\":1, \"listing\": [(id+1,pos)] } \n",
    "        else: \n",
    "          index[word]['freq']+=1 \n",
    "          index[word]['listing'].append((id+1,pos)) \n",
    "      for pos,word in enumerate(ext_words2): \n",
    "        if word not in index: \n",
    "          index[word]={ \"freq\":1, \"listing\": [(id+1,pos)] } \n",
    "        else: \n",
    "          index[word]['freq']+=1 \n",
    "          index[word]['listing'].append((id+1,pos)) \n",
    "    else:\n",
    "     print(\"No match found in\", filename) \n",
    "     #break\n",
    "print(\"\\n\")    \n",
    "from collections import OrderedDict \n",
    "index = OrderedDict(sorted(index.items())) \n",
    "with open(\"inverted.txt\",'w') as fp:\n",
    "  #print(\"Answer: \\n\") \n",
    "  for key in index: \n",
    "    print(f\"{key} : {index[key]}\") \n",
    "    fp.write(f\"{key} : {index[key]}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
